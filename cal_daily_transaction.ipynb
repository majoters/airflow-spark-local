{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785c8875-5b82-46ef-aefb-11a1ff3f7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, current_timestamp, date_sub, date_format, lit, to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4c7f89-dc2c-4084-a967-de5764d0e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"spark-nb\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22e3b77a-077d-47f3-855e-5f46fd350b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input table name\n",
    "data_table = \"local_db.sample_hive_table\"\n",
    "\n",
    "# Output table name\n",
    "output_table = \"local_db.daily_transaction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09f876fc-3d58-480f-a711-4b843aed1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current date (execution date) and calculate previous day's date\n",
    "execution_date = spark.sql(\"SELECT current_date() as current_date\").collect()[0][\"current_date\"]\n",
    "transaction_date = spark.sql(f\"SELECT date_sub('{execution_date}', 1) as transaction_date\").collect()[0][\"transaction_date\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b605510-4643-49d6-9fc0-fa6f4316bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input data\n",
    "data = spark.table(data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a96b58a-a2e4-4b03-8f85-d5dbf0587e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and calculate total transactions for the previous day\n",
    "daily_transaction = data \\\n",
    "    .filter(to_date(col(\"lpep_pickup_datetime\")) == lit(transaction_date)) \\\n",
    "    .agg(\n",
    "        lit(transaction_date).alias(\"transaction_date\"),\n",
    "        count(\"*\").alias(\"total_transactions\"),\n",
    "        date_format(current_timestamp(), \"yyyy-MM-dd HH:mm:ss\").alias(\"calculated_at\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1400518-1abe-46e0-8c30-342c667d4112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the result into the output table\n",
    "daily_transaction.write \\\n",
    "    .mode(\"append\") \\\n",
    "    .format(\"hive\") \\\n",
    "    .saveAsTable(output_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "566452e8-c390-42c5-b566-0ee43e4a1b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/sql/pandas/types.py:563: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if not is_datetime64tz_dtype(pser.dtype):\n",
      "/opt/spark/python/pyspark/sql/pandas/types.py:379: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if is_datetime64tz_dtype(s.dtype):\n",
      "/opt/spark/python/pyspark/sql/pandas/types.py:563: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if not is_datetime64tz_dtype(pser.dtype):\n",
      "/opt/spark/python/pyspark/sql/pandas/types.py:379: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if is_datetime64tz_dtype(s.dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-15 18:06:41</td>\n",
       "      <td>2024-02-15 18:08:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-15 17:53:07</td>\n",
       "      <td>2024-02-15 18:08:49</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>3.73</td>\n",
       "      <td>19.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-15 18:04:33</td>\n",
       "      <td>2024-02-15 18:08:17</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-9.80</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-15 18:04:33</td>\n",
       "      <td>2024-02-15 18:08:17</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>0.56</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.80</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-15 17:54:37</td>\n",
       "      <td>2024-02-15 18:08:08</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>14.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.90</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2024-02-15 18:06:41   2024-02-15 18:08:56                  N   \n",
       "1         2  2024-02-15 17:53:07   2024-02-15 18:08:49                  N   \n",
       "2         2  2024-02-15 18:04:33   2024-02-15 18:08:17                  N   \n",
       "3         2  2024-02-15 18:04:33   2024-02-15 18:08:17                  N   \n",
       "4         2  2024-02-15 17:54:37   2024-02-15 18:08:08                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0           1            75            75                1           0.71   \n",
       "1           1            82           138                1           3.73   \n",
       "2           1           247           247                1           0.56   \n",
       "3           1           247           247                1           0.56   \n",
       "4           1            75            42                1           2.60   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0          5.1    2.5      0.5        1.82           0.0        NaN   \n",
       "1         19.1    7.5      0.5        5.62           0.0        NaN   \n",
       "2         -5.8   -2.5     -0.5        0.00           0.0        NaN   \n",
       "3          5.8    2.5      0.5        0.00           0.0        NaN   \n",
       "4         14.9    2.5      0.5        0.00           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    1.0         10.92             1          1   \n",
       "1                    1.0         33.72             1          1   \n",
       "2                   -1.0         -9.80             4          1   \n",
       "3                    1.0          9.80             4          1   \n",
       "4                    1.0         18.90             2          1   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM local_db.sample_hive_table LIMIT 5\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ce09334-d054-47f2-971f-c1eb94620dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>total_transactions</th>\n",
       "      <th>calculated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-24</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-25 04:54:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-24</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-25 04:49:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_date  total_transactions        calculated_at\n",
       "0       2024-12-24                   0  2024-12-25 04:54:49\n",
       "1       2024-12-24                   0  2024-12-25 04:49:20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM local_db.daily_transaction LIMIT 5\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cf1be05-7198-4ab4-8b57-e0445f65f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"DROP TABLE IF EXISTS local_db.daily_transaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b87b5139-2de6-4442-99c4-d8f3dfc00c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "| local_db|   daily_transaction|      false|\n",
      "| local_db|   sample_hive_table|      false|\n",
      "| local_db|test_from_spark_s...|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN local_db\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b166207c-9010-4d9d-8b76-e6e5aa571b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e7e9e-2b70-4745-9f7b-49d01f633501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
